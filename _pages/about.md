---
layout: about
title: about
permalink: /

profile:
  align: right
  image: headshot.jpeg
  image_circular: true # crops the image to make it circular

news: true  # includes a list of news items
selected_papers: true # includes a list of papers marked as "selected={true}"
social: true  # includes social icons at the bottom of the page
---

I am a Dean's PhD Fellow at NYU, advised by <a href='https://scholar.google.com/citations?user=YeG8ZM0AAAAJ&hl=en'>Institute Associate Professor Chen Feng</a>. I am also a Graduate Fellow at <a href='https://research.nvidia.com/labs/avg/'>NVIDIA Research</a>, working on world simulators and foundation models with <a href='https://scholar.google.com/citations?user=RhOpyXcAAAAJ&hl=en'>Prof. Marco Pavone</a> at Stanford University. I am fortunate to collaborate with <a href='https://scholar.google.com/citations?hl=en&user=1VI_oYUAAAAJ'>Dr. Zhiding Yu</a> at <a href='https://research.nvidia.com/labs/lpr/'>NVIDIA Learning and Perception Research</a>, as well as <a href='https://scholar.google.com/citations?user=8KsqL4gAAAAJ&hl=en'>Dr. Zan Gojcjc</a> and <a href='https://scholar.google.com/citations?hl=en&user=CUlqK5EAAAAJ'>Prof. Sanja Fidler</a> at <a href='https://research.nvidia.com/labs/toronto-ai/'>NVIDIA Toronto AI Lab</a>.

Previously, I spent some time at NVIDIA AI Research with <a href='https://scholar.google.com/citations?user=bEcLezcAAAAJ&hl=en'>Prof. Anima Anandkumar</a>, NVIDIA Applied AV Research with <a href='https://scholar.google.com/citations?user=Oyx-_UIAAAAJ&hl=en'>Dr. Jose M. Alvarez</a>, Tsinghua MARS Lab with <a href='https://scholar.google.com/citations?user=DmahiOYAAAAJ&hl=en'>Prof. Hang Zhao</a>, and SJTU with <a href='https://scholar.google.com/citations?user=W_Q33RMAAAAJ&hl=en'>Prof. Siheng Chen</a>.

My research aims to *replicate human-like spatial intelligence with minimal human supervision*, paving the way for *trustworthy* and *accessible* autonomous robots and embodied agents working *for* and *around* humans. My current efforts are in three dimensions: (1) **agent**: building a generalist embodied visual agent powered by foundation models to perceive and act in 3D; (2) **world**: building a photorealistic world simulator to train and evaluate the foundation agents; (3) **data**: visual-spatial and multimodal dataset curation. 
